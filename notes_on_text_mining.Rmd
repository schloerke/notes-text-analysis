---
output: html_notebook
---

# Text analysis hierarchy

<img src="sentiment_analysis.jpg" width="1000px" />

# Packages

## Main Packages:

* tm: 
    * core library
    * text mining framework
    * http://tm.r-forge.r-project.org    
    * ftp://cran.r-project.org/pub/R/web/packages/tm/vignettes/tm.pdf
* qdap:
    * designed to assist in quantitative discourse analysis
    * https://trinker.github.io/qdap/
* tidytext: 
    * text mining in the "tidyverse"
    * http://tidytextmining.com/
* syuzhet: 
    * An R package for the extraction of sentiment and sentiment-based plot arcs from text
    * has link to stanford sentiment
    * https://github.com/mjockers/syuzhet
    * ftp://cran.r-project.org/pub/R/web/packages/syuzhet/vignettes/syuzhet-vignette.html
* sentimentr: 
    * similar to tidytext
    * trade off between speed an accuracy
        * faster than stanford, but not as accurate
        * slower than dictionaries, but more accurate
    * https://github.com/trinker/sentimentr
    * comparing syuzhet, rsentiment, and stanford: https://github.com/trinker/sentimentr#comparing-sentimentr-syuzhet-rsentiment-and-stanford


## Other packages:

* coreNLP:
    * Stanford library
    * "best" according to sentimentr and other sites
    * https://github.com/statsmaths/coreNLP
    * http://stanfordnlp.github.io/CoreNLP/


## Github packages:

* VADER:
    * specifically attuned to sentiments expressed in social media
    * https://github.com/cjhutto/vaderSentiment
* SpeedReader:
    * interested in heavy NLP applications in R, or working with an obscenely large corpus
    * https://github.com/matthewjdenny/SpeedReader
* sentiment140
    * R package for Twitter sentiment text analysis
    * https://github.com/okugami79/sentiment140
    

## Helper packages:

* SnowballC: 
    * word stemming algorithm for collapsing words to a common root to aid comparison of vocabulary
    * `?SnowballC::wordStem`
    * https://github.com/nalimilan/R.TeMiS
* hunspell: 
    * spell checker
    * http://hunspell.github.io
* tokenizers:
    * convert natural language text into tokens
    * https://github.com/ropensci/tokenizers


# Examples:

* rbloggers
    * https://www.r-bloggers.com/intro-to-text-analysis-with-r/
* basic text mining
    * https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html
* gentle intro (good explainations)
    * https://eight2late.wordpress.com/2015/05/27/a-gentle-introduction-to-text-mining-using-r/
* tm/qdap example
    * http://onepager.togaware.com/TextMiningO.pdf
* syuzhet:
    * http://juliasilge.com/blog/If-I-Loved-NLP-Less/
    * http://juliasilge.com/blog/You-Must-Allow-Me/
    


<!-- Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*. -->

<!-- When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). -->
